"""
FIFOç»Ÿè®¡åˆ†æå™¨

åŸºäºip_interface.pyä¸­çš„FIFOStatisticsç±»ï¼Œæä¾›ç»Ÿè®¡æ”¶é›†ã€åˆ†æå’Œå¯¼å‡ºåŠŸèƒ½ã€‚
"""

import csv
import os
import time
from datetime import datetime
from typing import Dict, List, Any
from pathlib import Path

from src.noc.base.ip_interface import PipelinedFIFO


class FIFOStatsCollector:
    """FIFOç»Ÿè®¡ä¿¡æ¯æ”¶é›†å™¨ï¼Œä½¿ç”¨PipelinedFIFOå†…ç½®çš„FIFOStatistics"""
    
    def __init__(self):
        self.fifo_registry = {}  # {fifo_identifier: {"fifo": obj, "node_id": str, "name": str}}
        
    def register_fifo(self, fifo: PipelinedFIFO, node_id: str = "", simplified_name: str = ""):
        """æ³¨å†Œéœ€è¦ç»Ÿè®¡çš„FIFO"""
        fifo_identifier = f"{node_id}_{simplified_name}"
        self.fifo_registry[fifo_identifier] = {
            "fifo": fifo,
            "node_id": node_id,
            "simplified_name": simplified_name
        }
        
    def collect_all_stats(self) -> List[Dict[str, Any]]:
        """æ”¶é›†æ‰€æœ‰æ³¨å†ŒFIFOçš„ç»Ÿè®¡ä¿¡æ¯"""
        collected_stats = []
        
        for identifier, info in self.fifo_registry.items():
            fifo = info["fifo"]
            stats = fifo.get_statistics()  # ä½¿ç”¨å†…ç½®ç»Ÿè®¡
            
            # æ·»åŠ æ ‡è¯†ä¿¡æ¯
            stats["èŠ‚ç‚¹ID"] = info["node_id"]
            stats["FIFOåç§°"] = info["simplified_name"]
            
            collected_stats.append(stats)
            
        return collected_stats
            
    def export_to_csv(self, filename: str = None, output_dir: str = "results") -> str:
        """å¯¼å‡ºç»Ÿè®¡æ•°æ®åˆ°CSVæ–‡ä»¶"""
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆç»Ÿä¸€ä½¿ç”¨Unixæ—¶é—´æˆ³æ ¼å¼ï¼‰
        if filename is None:
            timestamp = int(time.time())
            filename = f"fifo_statistics_{timestamp}"
            
        filepath = os.path.join(output_dir, f"{filename}.csv")
        
        collected_stats = self.collect_all_stats()
        if not collected_stats:
            print("âš ï¸ æ²¡æœ‰æ”¶é›†åˆ°FIFOç»Ÿè®¡æ•°æ®")
            return filepath
            
        # å®šä¹‰CSVåˆ—æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰- ç§»é™¤å†—ä½™åˆ—
        headers = [
            "èŠ‚ç‚¹ID", "FIFOåç§°", "æœ€å¤§å®¹é‡",
            "å½“å‰æ·±åº¦", "å³°å€¼æ·±åº¦", "å¹³å‡æ·±åº¦", "åˆ©ç”¨ç‡ç™¾åˆ†æ¯”",
            "ç©ºé˜Ÿåˆ—å‘¨æœŸæ•°", "æ»¡é˜Ÿåˆ—å‘¨æœŸæ•°",
            "æ€»å†™å…¥å°è¯•", "æˆåŠŸå†™å…¥æ¬¡æ•°", "æ€»è¯»å–å°è¯•", "æˆåŠŸè¯»å–æ¬¡æ•°",
            "å†™å…¥æ•ˆç‡", "è¯»å–æ•ˆç‡", "å†™å…¥é˜»å¡æ¬¡æ•°", "è¯»å–é˜»å¡æ¬¡æ•°",
            "æº¢å‡ºå°è¯•æ¬¡æ•°", "ä¸‹æº¢å°è¯•æ¬¡æ•°",
            "å¹³å‡åœç•™æ—¶é—´", "æœ€å°åœç•™æ—¶é—´", "æœ€å¤§åœç•™æ—¶é—´",
            "é«˜ä¼˜å…ˆçº§å†™å…¥", "æ€»ä»¿çœŸå‘¨æœŸ", "æ´»è·ƒå‘¨æœŸç™¾åˆ†æ¯”"
        ]
        
        # å†™å…¥CSVæ–‡ä»¶
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=headers)
            writer.writeheader()
            
            for stats in collected_stats:
                # ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å­˜åœ¨
                row = {}
                for header in headers:
                    row[header] = stats.get(header, 0)
                writer.writerow(row)
                
        print(f"ğŸ“Š FIFOç»Ÿè®¡æ•°æ®å·²å¯¼å‡ºåˆ°: {filepath}")
        print(f"ğŸ“ˆ å…±å¯¼å‡º {len(collected_stats)} ä¸ªFIFOçš„ç»Ÿè®¡ä¿¡æ¯")
        
        return filepath
        
    def get_summary_report(self) -> str:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦æŠ¥å‘Š"""
        collected_stats = self.collect_all_stats()
        if not collected_stats:
            return "æ²¡æœ‰æ”¶é›†åˆ°FIFOç»Ÿè®¡æ•°æ®"
            
        report = ["=" * 60]
        report.append("FIFO ç»Ÿè®¡æ‘˜è¦æŠ¥å‘Š")
        report.append("=" * 60)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_fifos = len(collected_stats)
        report.append(f"æ€»FIFOæ•°é‡: {total_fifos}")
        
        # æŒ‰èŠ‚ç‚¹åˆ†ç»„ç»Ÿè®¡
        nodes = set(stats["èŠ‚ç‚¹ID"] for stats in collected_stats)
        report.append(f"æ¶‰åŠèŠ‚ç‚¹æ•°: {len(nodes)}")
        
        # åˆ©ç”¨ç‡ç»Ÿè®¡
        utilizations = [stats["åˆ©ç”¨ç‡ç™¾åˆ†æ¯”"] for stats in collected_stats if stats["åˆ©ç”¨ç‡ç™¾åˆ†æ¯”"] > 0]
        if utilizations:
            avg_util = sum(utilizations) / len(utilizations)
            max_util = max(utilizations)
            min_util = min(utilizations)
            report.append(f"å¹³å‡åˆ©ç”¨ç‡: {avg_util:.2f}%")
            report.append(f"æœ€é«˜åˆ©ç”¨ç‡: {max_util:.2f}%")
            report.append(f"æœ€ä½åˆ©ç”¨ç‡: {min_util:.2f}%")
            
        # æ•ˆç‡ç»Ÿè®¡
        write_effs = [stats["å†™å…¥æ•ˆç‡"] for stats in collected_stats if stats["å†™å…¥æ•ˆç‡"] > 0]
        read_effs = [stats["è¯»å–æ•ˆç‡"] for stats in collected_stats if stats["è¯»å–æ•ˆç‡"] > 0]
        if write_effs:
            avg_write_eff = sum(write_effs) / len(write_effs)
            report.append(f"å¹³å‡å†™å…¥æ•ˆç‡: {avg_write_eff:.2f}%")
        if read_effs:
            avg_read_eff = sum(read_effs) / len(read_effs)
            report.append(f"å¹³å‡è¯»å–æ•ˆç‡: {avg_read_eff:.2f}%")
            
        # é˜»å¡ç»Ÿè®¡
        total_write_stalls = sum(stats["å†™å…¥é˜»å¡æ¬¡æ•°"] for stats in collected_stats)
        total_read_stalls = sum(stats["è¯»å–é˜»å¡æ¬¡æ•°"] for stats in collected_stats)
        report.append(f"æ€»å†™å…¥é˜»å¡æ¬¡æ•°: {total_write_stalls}")
        report.append(f"æ€»è¯»å–é˜»å¡æ¬¡æ•°: {total_read_stalls}")
        
        report.append("=" * 60)
        return "\n".join(report)
        
    def get_fifo_details(self, node_id: str = None, fifo_name_filter: str = None) -> List[Dict]:
        """è·å–ç‰¹å®šæ¡ä»¶ä¸‹çš„FIFOè¯¦ç»†ä¿¡æ¯"""
        collected_stats = self.collect_all_stats()
        
        filtered_stats = []
        for stats in collected_stats:
            if node_id is not None and stats["èŠ‚ç‚¹ID"] != node_id:
                continue
            if fifo_name_filter is not None and fifo_name_filter not in stats["FIFOåç§°"]:
                continue
            filtered_stats.append(stats)
            
        return filtered_stats