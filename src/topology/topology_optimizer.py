# -*- coding: utf-8 -*-
"""
æ‹“æ‰‘é…ç½®ä¼˜åŒ–å™¨
æ ¹æ®åº”ç”¨éœ€æ±‚æä¾›æœ€ä¼˜æ‹“æ‰‘é€‰æ‹©å’Œé…ç½®å»ºè®®
"""

from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import math


@dataclass
class ApplicationRequirements:
    """åº”ç”¨éœ€æ±‚å®šä¹‰"""

    chip_count: int
    budget_constraint: float  # é¢„ç®—çº¦æŸ (ç›¸å¯¹å€¼)
    latency_requirement: str  # 'low', 'medium', 'high'
    reliability_requirement: str  # 'low', 'medium', 'high'
    scalability_requirement: str  # 'low', 'medium', 'high'
    management_complexity: str  # 'simple', 'moderate', 'complex'
    power_constraint: float  # åŠŸè€—çº¦æŸ (ç›¸å¯¹å€¼)


@dataclass
class TopologyRecommendation:
    """æ‹“æ‰‘æ¨èç»“æœ"""

    topology_type: str
    configuration: Dict[str, Any]
    score: float
    pros: List[str]
    cons: List[str]
    optimization_tips: List[str]
    estimated_performance: Dict[str, float]


class TopologyOptimizer:
    """æ‹“æ‰‘é…ç½®ä¼˜åŒ–å™¨"""

    def __init__(self):
        # æ‹“æ‰‘ç‰¹æ€§é…ç½®
        self.topology_characteristics = {
            "tree": {"management_complexity": "simple", "cost_factor": "high", "fault_tolerance": "low", "scalability": "medium", "latency_base": "medium"},  # éœ€è¦é¢å¤–äº¤æ¢æœº
            "torus": {"management_complexity": "moderate", "cost_factor": "low", "fault_tolerance": "high", "scalability": "high", "latency_base": "low"},  # æ— éœ€é¢å¤–äº¤æ¢æœº
        }

        # æƒé‡é…ç½®
        self.requirement_weights = {"budget": 0.25, "latency": 0.20, "reliability": 0.20, "scalability": 0.15, "management": 0.10, "power": 0.10}

    def analyze_requirements(self, requirements: ApplicationRequirements) -> Dict[str, TopologyRecommendation]:
        """åˆ†æåº”ç”¨éœ€æ±‚å¹¶ç”Ÿæˆæ‹“æ‰‘æ¨è"""

        recommendations = {}

        # åˆ†æTreeæ‹“æ‰‘é€‚åˆåº¦
        tree_recommendation = self._analyze_tree_topology(requirements)
        recommendations["tree"] = tree_recommendation

        # åˆ†æTorusæ‹“æ‰‘é€‚åˆåº¦
        torus_recommendation = self._analyze_torus_topology(requirements)
        recommendations["torus"] = torus_recommendation

        return recommendations

    def _analyze_tree_topology(self, req: ApplicationRequirements) -> TopologyRecommendation:
        """åˆ†æTreeæ‹“æ‰‘çš„é€‚åˆåº¦"""

        # è®¡ç®—æœ€ä¼˜Treeé…ç½®
        optimal_config = self._optimize_tree_configuration(req.chip_count)

        # è®¡ç®—é€‚åˆåº¦è¯„åˆ†
        score = self._calculate_tree_score(req, optimal_config)

        # ç”Ÿæˆä¼˜ç¼ºç‚¹åˆ†æ
        pros, cons = self._analyze_tree_pros_cons(req, optimal_config)

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_tips = self._generate_tree_optimization_tips(req, optimal_config)

        # é¢„æµ‹æ€§èƒ½æŒ‡æ ‡
        estimated_performance = self._estimate_tree_performance(optimal_config)

        return TopologyRecommendation(
            topology_type="tree", configuration=optimal_config, score=score, pros=pros, cons=cons, optimization_tips=optimization_tips, estimated_performance=estimated_performance
        )

    def _analyze_torus_topology(self, req: ApplicationRequirements) -> TopologyRecommendation:
        """åˆ†æTorusæ‹“æ‰‘çš„é€‚åˆåº¦"""

        # è®¡ç®—æœ€ä¼˜Torusé…ç½®
        optimal_config = self._optimize_torus_configuration(req.chip_count)

        # è®¡ç®—é€‚åˆåº¦è¯„åˆ†
        score = self._calculate_torus_score(req, optimal_config)

        # ç”Ÿæˆä¼˜ç¼ºç‚¹åˆ†æ
        pros, cons = self._analyze_torus_pros_cons(req, optimal_config)

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_tips = self._generate_torus_optimization_tips(req, optimal_config)

        # é¢„æµ‹æ€§èƒ½æŒ‡æ ‡
        estimated_performance = self._estimate_torus_performance(optimal_config)

        return TopologyRecommendation(
            topology_type="torus", configuration=optimal_config, score=score, pros=pros, cons=cons, optimization_tips=optimization_tips, estimated_performance=estimated_performance
        )

    def _optimize_tree_configuration(self, chip_count: int) -> Dict[str, Any]:
        """ä¼˜åŒ–Treeæ‹“æ‰‘é…ç½®"""

        # è®¡ç®—æœ€ä¼˜äº¤æ¢æœºå®¹é‡
        if chip_count <= 16:
            optimal_capacity = 4
        elif chip_count <= 64:
            optimal_capacity = 8
        else:
            optimal_capacity = 16

        # ä¼°ç®—æ ‘çš„å±‚æ•°å’ŒèŠ‚ç‚¹æ•°
        levels = math.ceil(math.log(chip_count) / math.log(optimal_capacity))
        estimated_switches = max(0, (chip_count - 1) // (optimal_capacity - 1))
        total_nodes = chip_count + estimated_switches

        return {"switch_capacity": optimal_capacity, "estimated_levels": levels, "estimated_switches": estimated_switches, "total_nodes": total_nodes, "chip_count": chip_count}

    def _optimize_torus_configuration(self, chip_count: int) -> Dict[str, Any]:
        """ä¼˜åŒ–Torusæ‹“æ‰‘é…ç½®"""

        # é€‰æ‹©æœ€ä¼˜ç»´åº¦
        if chip_count <= 64:
            dimensions = 2
            # æ‰¾åˆ°æœ€æ¥è¿‘æ­£æ–¹å½¢çš„ç½‘æ ¼
            sqrt_n = int(math.sqrt(chip_count))
            for i in range(sqrt_n, 0, -1):
                if chip_count % i == 0:
                    grid_dims = [i, chip_count // i]
                    break
            else:
                # å¦‚æœæ— æ³•æ•´é™¤ï¼Œé€‰æ‹©æœ€æ¥è¿‘çš„
                grid_dims = [sqrt_n, math.ceil(chip_count / sqrt_n)]
        else:
            dimensions = 3
            # æ‰¾åˆ°æœ€æ¥è¿‘ç«‹æ–¹ä½“çš„ç½‘æ ¼
            cube_root = int(round(chip_count ** (1 / 3)))
            best_balance = float("inf")
            best_dims = [cube_root, cube_root, cube_root]

            for i in range(max(1, cube_root - 2), cube_root + 3):
                for j in range(max(1, cube_root - 2), cube_root + 3):
                    k = math.ceil(chip_count / (i * j))
                    if i * j * k >= chip_count:
                        balance = max(i, j, k) / min(i, j, k)
                        if balance < best_balance:
                            best_balance = balance
                            best_dims = [i, j, k]

            grid_dims = best_dims

        # è®¡ç®—ç½‘æ ¼å¹³è¡¡åº¦
        balance_factor = min(grid_dims) / max(grid_dims) if max(grid_dims) > 0 else 1.0

        return {"dimensions": dimensions, "grid_dimensions": grid_dims, "balance_factor": balance_factor, "total_nodes": chip_count, "chip_count": chip_count}

    def _calculate_tree_score(self, req: ApplicationRequirements, config: Dict) -> float:
        """è®¡ç®—Treeæ‹“æ‰‘é€‚åˆåº¦è¯„åˆ†"""
        score = 0.0

        # é¢„ç®—é€‚åˆåº¦ (Treeéœ€è¦æ›´å¤šç¡¬ä»¶)
        cost_factor = config["estimated_switches"] / config["chip_count"]
        budget_score = max(0, 1 - cost_factor) * req.budget_constraint
        score += self.requirement_weights["budget"] * budget_score

        # å»¶è¿Ÿé€‚åˆåº¦ (Treeåœ¨å°è§„æ¨¡æ—¶è¡¨ç°ä¸é”™)
        latency_multiplier = {"low": 0.5, "medium": 0.7, "high": 1.0}[req.latency_requirement]
        latency_score = max(0, 1 - config["estimated_levels"] * 0.1) * latency_multiplier
        score += self.requirement_weights["latency"] * latency_score

        # å¯é æ€§é€‚åˆåº¦ (Treeå®¹é”™æ€§è¾ƒä½)
        reliability_multiplier = {"low": 1.0, "medium": 0.6, "high": 0.3}[req.reliability_requirement]
        reliability_score = 0.4 * reliability_multiplier  # Treeå›ºæœ‰çš„ä½å¯é æ€§
        score += self.requirement_weights["reliability"] * reliability_score

        # å¯æ‰©å±•æ€§é€‚åˆåº¦
        scalability_multiplier = {"low": 1.0, "medium": 0.7, "high": 0.5}[req.scalability_requirement]
        scalability_score = max(0, 1 - math.log(config["total_nodes"]) * 0.1) * scalability_multiplier
        score += self.requirement_weights["scalability"] * scalability_score

        # ç®¡ç†å¤æ‚åº¦é€‚åˆåº¦ (Treeç®¡ç†ç®€å•)
        management_multiplier = {"simple": 1.0, "moderate": 0.8, "complex": 0.6}[req.management_complexity]
        management_score = 0.9 * management_multiplier
        score += self.requirement_weights["management"] * management_score

        # åŠŸè€—é€‚åˆåº¦ (TreeåŠŸè€—ç›¸å¯¹è¾ƒé«˜)
        power_score = max(0, 1 - cost_factor * 0.5) * req.power_constraint
        score += self.requirement_weights["power"] * power_score

        return min(1.0, score)

    def _calculate_torus_score(self, req: ApplicationRequirements, config: Dict) -> float:
        """è®¡ç®—Torusæ‹“æ‰‘é€‚åˆåº¦è¯„åˆ†"""
        score = 0.0

        # é¢„ç®—é€‚åˆåº¦ (Torusæ— éœ€é¢å¤–ç¡¬ä»¶)
        budget_score = 1.0 * req.budget_constraint
        score += self.requirement_weights["budget"] * budget_score

        # å»¶è¿Ÿé€‚åˆåº¦ (Toruså»¶è¿Ÿé€šå¸¸è¾ƒä½)
        latency_multiplier = {"low": 1.0, "medium": 0.8, "high": 0.6}[req.latency_requirement]
        avg_distance = sum(config["grid_dimensions"]) / len(config["grid_dimensions"]) / 4
        latency_score = max(0, 1 - avg_distance * 0.2) * latency_multiplier
        score += self.requirement_weights["latency"] * latency_score

        # å¯é æ€§é€‚åˆåº¦ (Toruså®¹é”™æ€§é«˜)
        reliability_multiplier = {"low": 0.7, "medium": 0.9, "high": 1.0}[req.reliability_requirement]
        reliability_base = 0.8 + config["dimensions"] * 0.1  # ç»´åº¦è¶Šé«˜å¯é æ€§è¶Šå¥½
        reliability_score = min(1.0, reliability_base) * reliability_multiplier
        score += self.requirement_weights["reliability"] * reliability_score

        # å¯æ‰©å±•æ€§é€‚åˆåº¦ (Torusæ‰©å±•æ€§å¥½)
        scalability_multiplier = {"low": 0.7, "medium": 0.9, "high": 1.0}[req.scalability_requirement]
        scalability_score = (0.7 + config["balance_factor"] * 0.3) * scalability_multiplier
        score += self.requirement_weights["scalability"] * scalability_score

        # ç®¡ç†å¤æ‚åº¦é€‚åˆåº¦ (Torusç®¡ç†ä¸­ç­‰å¤æ‚)
        management_multiplier = {"simple": 0.6, "moderate": 1.0, "complex": 0.8}[req.management_complexity]
        management_score = 0.7 * management_multiplier
        score += self.requirement_weights["management"] * management_score

        # åŠŸè€—é€‚åˆåº¦ (TorusåŠŸè€—è¾ƒä½)
        power_score = 0.9 * req.power_constraint
        score += self.requirement_weights["power"] * power_score

        return min(1.0, score)

    def _analyze_tree_pros_cons(self, req: ApplicationRequirements, config: Dict) -> Tuple[List[str], List[str]]:
        """åˆ†æTreeæ‹“æ‰‘çš„ä¼˜ç¼ºç‚¹"""
        pros = ["ç®¡ç†å’Œé…ç½®ç›¸å¯¹ç®€å•", "æ”¯æŒå±‚æ¬¡åŒ–æ§åˆ¶ç»“æ„", "é€‚åˆé›†ä¸­å¼ç®¡ç†åœºæ™¯", "è°ƒè¯•å’Œæ•…éšœå®šä½å®¹æ˜“"]

        cons = [f"éœ€è¦é¢å¤–çš„{config['estimated_switches']}ä¸ªäº¤æ¢æœºè®¾å¤‡", "å•ç‚¹æ•…éšœå½±å“è¾ƒå¤§", "éšè§„æ¨¡å¢é•¿æ€§èƒ½ä¸‹é™æ˜æ˜¾", "ç¡¬ä»¶æˆæœ¬è¾ƒé«˜"]

        # æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´
        if req.chip_count <= 16:
            pros.append("å°è§„æ¨¡æ—¶æ€§èƒ½è¡¨ç°è‰¯å¥½")
        else:
            cons.append("å¤§è§„æ¨¡æ—¶è·¯å¾„é•¿åº¦å¢åŠ æ˜æ˜¾")

        if req.reliability_requirement == "high":
            cons.append("ä¸æ»¡è¶³é«˜å¯é æ€§è¦æ±‚")

        return pros, cons

    def _analyze_torus_pros_cons(self, req: ApplicationRequirements, config: Dict) -> Tuple[List[str], List[str]]:
        """åˆ†æTorusæ‹“æ‰‘çš„ä¼˜ç¼ºç‚¹"""
        pros = ["æ— éœ€é¢å¤–äº¤æ¢æœºï¼Œç¡¬ä»¶æˆæœ¬ä½", "å…·æœ‰å¤šè·¯å¾„å†—ä½™ï¼Œå®¹é”™æ€§å¥½", "å¹³å‡è·¯å¾„é•¿åº¦çŸ­ï¼Œå»¶è¿Ÿä½", "æ‰©å±•æ€§ä¼˜ç§€ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²"]

        cons = ["åˆå§‹é…ç½®å’Œè°ƒè¯•è¾ƒå¤æ‚", "éœ€è¦è§„åˆ™çš„ç½‘æ ¼å¸ƒå±€", "è·¯ç”±ç®—æ³•ç›¸å¯¹å¤æ‚"]

        # æ ¹æ®å…·ä½“é…ç½®è°ƒæ•´
        if config["balance_factor"] > 0.8:
            pros.append(f"ç½‘æ ¼å¹³è¡¡åº¦é«˜({config['balance_factor']:.2f})ï¼Œæ€§èƒ½optimal")
        else:
            cons.append(f"ç½‘æ ¼ä¸å¤Ÿå¹³è¡¡({config['balance_factor']:.2f})ï¼Œå¯èƒ½å½±å“æ€§èƒ½")

        if config["dimensions"] == 3:
            pros.append("3Dæ‹“æ‰‘æä¾›æ›´å¥½çš„å¯æ‰©å±•æ€§")
            cons.append("3Då¸ƒå±€å’Œç®¡ç†æ›´å¤æ‚")

        return pros, cons

    def _generate_tree_optimization_tips(self, req: ApplicationRequirements, config: Dict) -> List[str]:
        """ç”ŸæˆTreeæ‹“æ‰‘ä¼˜åŒ–å»ºè®®"""
        tips = []

        # äº¤æ¢æœºé…ç½®ä¼˜åŒ–
        if config["switch_capacity"] < 8:
            tips.append(f"è€ƒè™‘ä½¿ç”¨æ›´å¤§å®¹é‡çš„äº¤æ¢æœº(å½“å‰{config['switch_capacity']})æ¥å‡å°‘å±‚æ•°")

        # è§„æ¨¡ä¼˜åŒ–å»ºè®®
        if req.chip_count > 64:
            tips.append("å¤§è§„æ¨¡éƒ¨ç½²æ—¶è€ƒè™‘åˆ†å±‚Treeæˆ–æ··åˆæ‹“æ‰‘")

        # å¯é æ€§ä¼˜åŒ–
        if req.reliability_requirement in ["medium", "high"]:
            tips.append("æ·»åŠ å†—ä½™äº¤æ¢æœºé“¾è·¯æé«˜å¯é æ€§")
            tips.append("å®æ–½æ•…éšœå¿«é€Ÿæ£€æµ‹å’Œæ¢å¤æœºåˆ¶")

        # æˆæœ¬ä¼˜åŒ–
        if req.budget_constraint < 0.7:
            tips.append("é€‰æ‹©æ€§èƒ½ä»·æ ¼æ¯”æ›´å¥½çš„äº¤æ¢æœºè®¾å¤‡")
            tips.append("è€ƒè™‘åˆ†é˜¶æ®µéƒ¨ç½²ç­–ç•¥")

        return tips

    def _generate_torus_optimization_tips(self, req: ApplicationRequirements, config: Dict) -> List[str]:
        """ç”ŸæˆTorusæ‹“æ‰‘ä¼˜åŒ–å»ºè®®"""
        tips = []

        # ç½‘æ ¼ä¼˜åŒ–å»ºè®®
        if config["balance_factor"] < 0.7:
            dims_str = "x".join(map(str, config["grid_dimensions"]))
            tips.append(f"å½“å‰ç½‘æ ¼({dims_str})ä¸å¤Ÿå¹³è¡¡ï¼Œè€ƒè™‘è°ƒæ•´ä¸ºæ›´æ–¹å½¢çš„å¸ƒå±€")

        # ç»´åº¦é€‰æ‹©ä¼˜åŒ–
        if req.chip_count > 100 and config["dimensions"] == 2:
            tips.append("å¤§è§„æ¨¡éƒ¨ç½²å»ºè®®ä½¿ç”¨3D Torusä»¥è·å¾—æ›´å¥½æ€§èƒ½")

        # è·¯ç”±ä¼˜åŒ–
        if req.latency_requirement == "low":
            tips.append("ä½¿ç”¨æœ€çŸ­è·¯å¾„ä¼˜å…ˆçš„è·¯ç”±ç®—æ³•")
            tips.append("å®æ–½è‡ªé€‚åº”è·¯ç”±ä»¥é¿å¼€æ‹¥å¡é“¾è·¯")

        # å¯é æ€§ä¼˜åŒ–
        if req.reliability_requirement == "high":
            tips.append("å¯ç”¨æ•…éšœé“¾è·¯çš„æ—è·¯æœºåˆ¶")
            tips.append("å®æ–½åˆ†å¸ƒå¼è·¯ç”±è¡¨æ›´æ–°")

        # ç®¡ç†ä¼˜åŒ–
        if req.management_complexity == "simple":
            tips.append("ä½¿ç”¨å¯è§†åŒ–å·¥å…·ç®€åŒ–æ‹“æ‰‘ç®¡ç†")
            tips.append("å®æ–½è‡ªåŠ¨åŒ–é…ç½®å’Œç›‘æ§")

        return tips

    def _estimate_tree_performance(self, config: Dict) -> Dict[str, float]:
        """é¢„æµ‹Treeæ‹“æ‰‘æ€§èƒ½"""
        avg_path_length = config["estimated_levels"] * 0.7  # ä¼°ç®—å¹³å‡è·¯å¾„é•¿åº¦
        max_path_length = config["estimated_levels"] * 2  # ä¼°ç®—æœ€å¤§è·¯å¾„é•¿åº¦

        return {
            "avg_path_length": avg_path_length,
            "max_path_length": max_path_length,
            "bandwidth_efficiency": config["chip_count"] / config["total_nodes"],
            "cost_factor": config["estimated_switches"] / config["chip_count"],
            "fault_tolerance": max(0.1, 1 - config["estimated_switches"] / config["total_nodes"]),
        }

    def _estimate_torus_performance(self, config: Dict) -> Dict[str, float]:
        """é¢„æµ‹Torusæ‹“æ‰‘æ€§èƒ½"""
        # ä¼°ç®—å¹³å‡è·¯å¾„é•¿åº¦
        avg_path_length = sum(dim / 4 for dim in config["grid_dimensions"])
        max_path_length = sum(dim // 2 for dim in config["grid_dimensions"])

        return {
            "avg_path_length": avg_path_length,
            "max_path_length": max_path_length,
            "bandwidth_efficiency": 1.0,  # æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯èŠ¯ç‰‡
            "cost_factor": 0.0,  # æ— é¢å¤–äº¤æ¢æœº
            "fault_tolerance": min(0.95, 0.5 + config["dimensions"] * 0.15),
        }

    def generate_optimization_report(self, requirements: ApplicationRequirements) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®æŠ¥å‘Š"""
        recommendations = self.analyze_requirements(requirements)

        # æ‰¾åˆ°æœ€ä½³æ¨è
        best_topology = max(recommendations.keys(), key=lambda k: recommendations[k].score)

        report = []
        report.append("# æ‹“æ‰‘é…ç½®ä¼˜åŒ–å»ºè®®æŠ¥å‘Š\n")

        # éœ€æ±‚åˆ†æ
        report.append("## åº”ç”¨éœ€æ±‚åˆ†æ\n")
        report.append(f"- èŠ¯ç‰‡æ•°é‡: {requirements.chip_count}\n")
        report.append(f"- é¢„ç®—çº¦æŸ: {requirements.budget_constraint:.1f}\n")
        report.append(f"- å»¶è¿Ÿè¦æ±‚: {requirements.latency_requirement}\n")
        report.append(f"- å¯é æ€§è¦æ±‚: {requirements.reliability_requirement}\n")
        report.append(f"- å¯æ‰©å±•æ€§è¦æ±‚: {requirements.scalability_requirement}\n")
        report.append(f"- ç®¡ç†å¤æ‚åº¦: {requirements.management_complexity}\n")
        report.append(f"- åŠŸè€—çº¦æŸ: {requirements.power_constraint:.1f}\n\n")

        # æœ€ä½³æ¨è
        best_rec = recommendations[best_topology]
        report.append(f"## æ¨èæ–¹æ¡ˆ: {best_topology.upper()}æ‹“æ‰‘\n")
        report.append(f"**é€‚åˆåº¦è¯„åˆ†: {best_rec.score:.3f}**\n\n")

        # é…ç½®è¯¦æƒ…
        report.append("### é…ç½®è¯¦æƒ…\n")
        for key, value in best_rec.configuration.items():
            report.append(f"- {key}: {value}\n")
        report.append("\n")

        # ä¼˜ç¼ºç‚¹åˆ†æ
        report.append("### ä¼˜åŠ¿\n")
        for pro in best_rec.pros:
            report.append(f"+ {pro}\n")
        report.append("\n")

        report.append("### å±€é™æ€§\n")
        for con in best_rec.cons:
            report.append(f"- {con}\n")
        report.append("\n")

        # ä¼˜åŒ–å»ºè®®
        report.append("### ä¼˜åŒ–å»ºè®®\n")
        for tip in best_rec.optimization_tips:
            report.append(f"ğŸ’¡ {tip}\n")
        report.append("\n")

        # æ€§èƒ½é¢„æµ‹
        report.append("### æ€§èƒ½é¢„æµ‹\n")
        for metric, value in best_rec.estimated_performance.items():
            report.append(f"- {metric}: {value:.3f}\n")
        report.append("\n")

        # æ›¿ä»£æ–¹æ¡ˆ
        alternative_topology = "torus" if best_topology == "tree" else "tree"
        alt_rec = recommendations[alternative_topology]
        report.append(f"## æ›¿ä»£æ–¹æ¡ˆ: {alternative_topology.upper()}æ‹“æ‰‘\n")
        report.append(f"**é€‚åˆåº¦è¯„åˆ†: {alt_rec.score:.3f}**\n")
        report.append("å¦‚æœä¸»è¦æ–¹æ¡ˆä¸é€‚ç”¨ï¼Œå¯ä»¥è€ƒè™‘æ­¤æ›¿ä»£æ–¹æ¡ˆã€‚\n\n")

        return "".join(report)


def create_sample_requirements() -> List[Tuple[str, ApplicationRequirements]]:
    """åˆ›å»ºç¤ºä¾‹åº”ç”¨éœ€æ±‚"""
    scenarios = [
        (
            "å¼€å‘æµ‹è¯•ç¯å¢ƒ",
            ApplicationRequirements(
                chip_count=8, budget_constraint=0.6, latency_requirement="medium", reliability_requirement="low", scalability_requirement="low", management_complexity="simple", power_constraint=0.7
            ),
        ),
        (
            "ç”Ÿäº§ç¯å¢ƒé›†ç¾¤",
            ApplicationRequirements(
                chip_count=64, budget_constraint=0.8, latency_requirement="low", reliability_requirement="high", scalability_requirement="high", management_complexity="moderate", power_constraint=0.6
            ),
        ),
        (
            "é«˜æ€§èƒ½è®¡ç®—",
            ApplicationRequirements(
                chip_count=256, budget_constraint=0.9, latency_requirement="low", reliability_requirement="high", scalability_requirement="high", management_complexity="complex", power_constraint=0.5
            ),
        ),
    ]

    return scenarios


if __name__ == "__main__":
    # æ¼”ç¤ºä¼˜åŒ–å™¨åŠŸèƒ½
    optimizer = TopologyOptimizer()
    scenarios = create_sample_requirements()

    for scenario_name, requirements in scenarios:
        print(f"\n{'='*50}")
        print(f"åœºæ™¯: {scenario_name}")
        print(f"{'='*50}")

        report = optimizer.generate_optimization_report(requirements)
        print(report)
