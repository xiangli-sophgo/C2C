#!/usr/bin/env python3
"""
NoC åˆ†ææ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„åˆ†æå’Œå¯è§†åŒ–åŠŸèƒ½
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.noc.analysis import ResultProcessor, PerformanceVisualizer, NetworkFlowVisualizer
from src.noc.analysis.performance_metrics import RequestMetrics, RequestType
import numpy as np
import matplotlib.pyplot as plt


def create_sample_requests(num_requests: int = 1000) -> list:
    """åˆ›å»ºç¤ºä¾‹è¯·æ±‚æ•°æ®"""
    requests = []
    
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ
    
    for i in range(num_requests):
        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„è¯·æ±‚
        request_type = RequestType.READ if np.random.random() < 0.6 else RequestType.WRITE
        
        # éšæœºé€‰æ‹©æºå’Œç›®æ ‡èŠ‚ç‚¹
        source_node = np.random.randint(0, 16)
        dest_node = np.random.randint(0, 16)
        while dest_node == source_node:
            dest_node = np.random.randint(0, 16)
        
        # æ¨¡æ‹Ÿæ—¶é—´å‚æ•°
        start_time = np.random.randint(0, 10000)
        cmd_latency = np.random.randint(50, 150)
        data_latency = np.random.randint(100, 300)
        network_latency = np.random.randint(20, 80)
        end_time = start_time + cmd_latency + data_latency + network_latency
        
        # æ¨¡æ‹Ÿæ•°æ®é‡
        burst_size = np.random.choice([1, 2, 4, 8])
        total_bytes = burst_size * 128  # å‡è®¾æ¯ä¸ªflit 128å­—èŠ‚
        
        # è®¡ç®—è·³æ•°ï¼ˆåŸºäºæ›¼å“ˆé¡¿è·ç¦»ï¼‰
        src_x, src_y = source_node % 4, source_node // 4
        dst_x, dst_y = dest_node % 4, dest_node // 4
        hop_count = abs(src_x - dst_x) + abs(src_y - dst_y)
        
        request = RequestMetrics(
            packet_id=f"req_{i}",
            request_type=request_type,
            source_node=source_node,
            dest_node=dest_node,
            burst_size=burst_size,
            start_time=start_time,
            end_time=end_time,
            cmd_latency=cmd_latency,
            data_latency=data_latency,
            network_latency=network_latency,
            total_bytes=total_bytes,
            hop_count=hop_count,
            path_nodes=list(range(source_node, dest_node + 1))  # ç®€åŒ–è·¯å¾„
        )
        
        requests.append(request)
    
    return requests


def demonstrate_analysis():
    """æ¼”ç¤ºåˆ†æåŠŸèƒ½"""
    print("=" * 60)
    print("NoC æ€§èƒ½åˆ†ææ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    print("\n1. åˆ›å»ºç¤ºä¾‹è¯·æ±‚æ•°æ®...")
    requests = create_sample_requests(1000)
    print(f"   åˆ›å»ºäº† {len(requests)} ä¸ªè¯·æ±‚")
    
    # åˆå§‹åŒ–ç»“æœå¤„ç†å™¨
    print("\n2. åˆå§‹åŒ–ç»“æœå¤„ç†å™¨...")
    config = {
        'topology_type': 'mesh_4x4',
        'node_count': 16,
        'gap_threshold_ns': 200,
        'window_size_ns': 1000,
        'congestion_threshold': 0.8
    }
    
    processor = ResultProcessor(config)
    
    # æ·»åŠ è¯·æ±‚æ•°æ®
    print("\n3. æ·»åŠ è¯·æ±‚æ•°æ®åˆ°å¤„ç†å™¨...")
    for req in requests:
        processor.performance_metrics.add_request(req)
    
    # æ‰§è¡Œæ€§èƒ½åˆ†æ
    print("\n4. æ‰§è¡Œæ€§èƒ½åˆ†æ...")
    network_metrics = processor.analyze_performance()
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    print("\n5. åˆ†æç»“æœæ‘˜è¦:")
    print("-" * 40)
    summary = processor.get_performance_summary()
    
    for key, value in summary.items():
        if isinstance(value, float):
            print(f"   {key}: {value:.3f}")
        else:
            print(f"   {key}: {value}")
    
    return processor, network_metrics, requests


def demonstrate_visualization(processor, network_metrics, requests):
    """æ¼”ç¤ºå¯è§†åŒ–åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("NoC å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = PerformanceVisualizer()
    
    # 1. å¸¦å®½åˆ†æå›¾
    print("\n1. ç”Ÿæˆå¸¦å®½åˆ†æå›¾...")
    fig1 = visualizer.plot_bandwidth_analysis(network_metrics, 'bandwidth_analysis.png')
    print("   ä¿å­˜ä¸º: bandwidth_analysis.png")
    
    # 2. å»¶è¿Ÿåˆ†æå›¾
    print("\n2. ç”Ÿæˆå»¶è¿Ÿåˆ†æå›¾...")
    fig2 = visualizer.plot_latency_analysis(network_metrics, 'latency_analysis.png')
    print("   ä¿å­˜ä¸º: latency_analysis.png")
    
    # 3. ååé‡åˆ†æå›¾
    print("\n3. ç”Ÿæˆååé‡åˆ†æå›¾...")
    fig3 = visualizer.plot_throughput_analysis(network_metrics, 'throughput_analysis.png')
    print("   ä¿å­˜ä¸º: throughput_analysis.png")
    
    # 4. çƒ­ç‚¹åˆ†æå›¾
    print("\n4. ç”Ÿæˆçƒ­ç‚¹åˆ†æå›¾...")
    fig4 = visualizer.plot_hotspot_analysis(network_metrics, 'hotspot_analysis.png')
    print("   ä¿å­˜ä¸º: hotspot_analysis.png")
    
    # 5. æ€§èƒ½ä»ªè¡¨æ¿
    print("\n5. ç”Ÿæˆæ€§èƒ½ä»ªè¡¨æ¿...")
    fig5 = visualizer.create_performance_dashboard(network_metrics, 'performance_dashboard.png')
    print("   ä¿å­˜ä¸º: performance_dashboard.png")
    
    # 6. ç½‘ç»œæµé‡å¯è§†åŒ–
    print("\n6. ç”Ÿæˆç½‘ç»œæµé‡å¯è§†åŒ–...")
    flow_visualizer = NetworkFlowVisualizer(layout='grid')
    topology_info = {'rows': 4, 'cols': 4}
    fig6 = flow_visualizer.visualize_network_flow(requests, topology_info, 'network_flow.png')
    print("   ä¿å­˜ä¸º: network_flow.png")
    
    # æ˜¾ç¤ºæ‰€æœ‰å›¾è¡¨
    print("\n7. æ˜¾ç¤ºå›¾è¡¨...")
    plt.show()


def demonstrate_export(processor):
    """æ¼”ç¤ºå¯¼å‡ºåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("NoC ç»“æœå¯¼å‡ºæ¼”ç¤º")
    print("=" * 60)
    
    # 1. å¯¼å‡ºJSON
    print("\n1. å¯¼å‡ºJSONæ ¼å¼...")
    json_result = processor.export_results('json', 'noc_results.json')
    print(f"   å¯¼å‡ºç»“æœ: {json_result}")
    
    # 2. å¯¼å‡ºCSV
    print("\n2. å¯¼å‡ºCSVæ ¼å¼...")
    csv_result = processor.export_results('csv', 'noc_results.csv')
    print(f"   å¯¼å‡ºç»“æœ: {csv_result}")
    
    # 3. å¯¼å‡ºExcel
    print("\n3. å¯¼å‡ºExcelæ ¼å¼...")
    try:
        excel_result = processor.export_results('excel', 'noc_results.xlsx')
        print(f"   å¯¼å‡ºç»“æœ: {excel_result}")
    except ImportError:
        print("   éœ€è¦å®‰è£… openpyxl æ¥æ”¯æŒExcelå¯¼å‡º")
        print("   è¿è¡Œ: pip install openpyxl")


def demonstrate_advanced_analysis(processor):
    """æ¼”ç¤ºé«˜çº§åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("NoC é«˜çº§åˆ†ææ¼”ç¤º")
    print("=" * 60)
    
    requests = processor.performance_metrics.requests
    
    # 1. æŒ‰è·³æ•°åˆ†æå»¶è¿Ÿ
    print("\n1. æŒ‰è·³æ•°åˆ†æå»¶è¿Ÿ...")
    latency_by_distance = processor.latency_analyzer.analyze_latency_by_distance(requests)
    
    print("   è·³æ•° -> å¹³å‡å»¶è¿Ÿ:")
    for hop_count, latency_metrics in sorted(latency_by_distance.items()):
        print(f"     {hop_count} è·³: {latency_metrics.avg_total_latency:.1f} ns")
    
    # 2. æŒ‰èŠ‚ç‚¹å¯¹åˆ†æå»¶è¿Ÿ
    print("\n2. èŠ‚ç‚¹å¯¹å»¶è¿Ÿåˆ†æï¼ˆæ˜¾ç¤ºå‰5ä¸ªï¼‰...")
    latency_by_node_pair = processor.latency_analyzer.analyze_latency_by_node_pair(requests)
    
    # æŒ‰å¹³å‡å»¶è¿Ÿæ’åº
    sorted_pairs = sorted(latency_by_node_pair.items(), 
                         key=lambda x: x[1].avg_total_latency, reverse=True)
    
    print("   èŠ‚ç‚¹å¯¹ -> å¹³å‡å»¶è¿Ÿ:")
    for (src, dst), latency_metrics in sorted_pairs[:5]:
        print(f"     {src} -> {dst}: {latency_metrics.avg_total_latency:.1f} ns")
    
    # 3. çƒ­ç‚¹åˆ†æ
    print("\n3. çƒ­ç‚¹èŠ‚ç‚¹åˆ†æ...")
    hotspots = processor.hotspot_analyzer.analyze_hotspots(requests)
    
    print("   çƒ­ç‚¹èŠ‚ç‚¹:")
    for hotspot in hotspots[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
        status = "ğŸ”¥ çƒ­ç‚¹" if hotspot.is_hotspot else "âœ… æ­£å¸¸"
        print(f"     èŠ‚ç‚¹ {hotspot.node_id}: {status}")
        print(f"       æ‹¥å¡æ¯”ä¾‹: {hotspot.congestion_ratio:.2f}")
        print(f"       å¸¦å®½åˆ©ç”¨ç‡: {hotspot.bandwidth_utilization:.2f}")
        print(f"       è´Ÿè½½å‡è¡¡: {hotspot.load_balance_ratio:.2f}")
    
    # 4. å·¥ä½œåŒºé—´åˆ†æ
    print("\n4. å·¥ä½œåŒºé—´åˆ†æ...")
    overall_bandwidth = processor.bandwidth_analyzer.calculate_bandwidth_metrics(requests)
    
    print(f"   æ€»å·¥ä½œåŒºé—´æ•°: {len(overall_bandwidth.working_intervals)}")
    print(f"   æ€»å·¥ä½œæ—¶é—´: {overall_bandwidth.total_working_time} ns")
    print(f"   åˆ©ç”¨ç‡: {overall_bandwidth.utilization_ratio:.2%}")
    print(f"   æœ‰æ•ˆå¸¦å®½: {overall_bandwidth.effective_bandwidth_gbps:.3f} GB/s")


def print_feature_summary():
    """æ‰“å°åŠŸèƒ½æ€»ç»“"""
    print("\n" + "=" * 60)
    print("NoC åˆ†ææ¨¡å—åŠŸèƒ½æ€»ç»“")
    print("=" * 60)
    
    features = [
        "ğŸ“Š æ€§èƒ½æŒ‡æ ‡åˆ†æ",
        "   â€¢ å¸¦å®½åˆ†æ (å¹³å‡/å³°å€¼/æœ‰æ•ˆå¸¦å®½)",
        "   â€¢ å»¶è¿Ÿåˆ†æ (å¹³å‡/P50/P95/P99å»¶è¿Ÿ)",
        "   â€¢ ååé‡åˆ†æ (å¹³å‡/å³°å€¼/æŒç»­ååé‡)",
        "   â€¢ å·¥ä½œåŒºé—´åˆ†æ",
        "",
        "ğŸ”¥ çƒ­ç‚¹åˆ†æ",
        "   â€¢ èŠ‚ç‚¹æµé‡ç»Ÿè®¡",
        "   â€¢ æ‹¥å¡æ£€æµ‹",
        "   â€¢ è´Ÿè½½å‡è¡¡åˆ†æ",
        "   â€¢ çƒ­ç‚¹èŠ‚ç‚¹è¯†åˆ«",
        "",
        "ğŸ“ˆ å¯è§†åŒ–åŠŸèƒ½",
        "   â€¢ å¸¦å®½åˆ†æå›¾è¡¨",
        "   â€¢ å»¶è¿Ÿåˆ†å¸ƒå›¾",
        "   â€¢ ååé‡æ—¶é—´åºåˆ—",
        "   â€¢ çƒ­ç‚¹åˆ†æå›¾",
        "   â€¢ æ€§èƒ½ä»ªè¡¨æ¿",
        "   â€¢ ç½‘ç»œæµé‡å›¾",
        "",
        "ğŸ’¾ å¯¼å‡ºåŠŸèƒ½",
        "   â€¢ JSON æ ¼å¼å¯¼å‡º",
        "   â€¢ CSV æ ¼å¼å¯¼å‡º",
        "   â€¢ Excel æ ¼å¼å¯¼å‡º",
        "",
        "ğŸ”§ é«˜çº§åˆ†æ",
        "   â€¢ æŒ‰è·³æ•°åˆ†æå»¶è¿Ÿ",
        "   â€¢ æŒ‰èŠ‚ç‚¹å¯¹åˆ†æ",
        "   â€¢ æ—¶é—´çª—å£åˆ†æ",
        "   â€¢ ç½‘ç»œåˆ©ç”¨ç‡åˆ†æ",
        "",
        "ğŸ“‹ ä¸åŸç‰ˆçš„æ”¹è¿›",
        "   â€¢ æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•",
        "   â€¢ ç±»å‹å®‰å…¨çš„æ•°æ®ç»“æ„",
        "   â€¢ ç°ä»£åŒ–çš„å¯è§†åŒ–ç•Œé¢",
        "   â€¢ æ”¯æŒå¤šç§å¯¼å‡ºæ ¼å¼",
        "   â€¢ è¯¦ç»†çš„æ€§èƒ½æŒ‡æ ‡è®¡ç®—",
        "   â€¢ æ™ºèƒ½çš„çƒ­ç‚¹æ£€æµ‹ç®—æ³•"
    ]
    
    for feature in features:
        print(feature)


def main():
    """ä¸»å‡½æ•°"""
    print("NoC æ€§èƒ½åˆ†æå’Œå¯è§†åŒ–æ¼”ç¤º")
    print("åŸºäºæ–°çš„åˆ†ææ¡†æ¶ï¼Œæä¾›å…¨é¢çš„æ€§èƒ½åˆ†æèƒ½åŠ›")
    
    try:
        # æ‰§è¡Œæ¼”ç¤º
        processor, network_metrics, requests = demonstrate_analysis()
        demonstrate_visualization(processor, network_metrics, requests)
        demonstrate_export(processor)
        demonstrate_advanced_analysis(processor)
        print_feature_summary()
        
        print("\n" + "=" * 60)
        print("æ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        print("ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  â€¢ bandwidth_analysis.png - å¸¦å®½åˆ†æå›¾")
        print("  â€¢ latency_analysis.png - å»¶è¿Ÿåˆ†æå›¾")
        print("  â€¢ throughput_analysis.png - ååé‡åˆ†æå›¾")
        print("  â€¢ hotspot_analysis.png - çƒ­ç‚¹åˆ†æå›¾")
        print("  â€¢ performance_dashboard.png - æ€§èƒ½ä»ªè¡¨æ¿")
        print("  â€¢ network_flow.png - ç½‘ç»œæµé‡å›¾")
        print("  â€¢ noc_results.json - JSONæ ¼å¼ç»“æœ")
        print("  â€¢ noc_results.csv - CSVæ ¼å¼ç»“æœ")
        print("  â€¢ noc_results.xlsx - Excelæ ¼å¼ç»“æœ")
        print("\nè¦åœ¨å®é™…é¡¹ç›®ä¸­ä½¿ç”¨ï¼Œè¯·å‚è€ƒ:")
        print("  from src.noc.analysis import ResultProcessor")
        print("  processor = ResultProcessor(config)")
        print("  processor.collect_simulation_data(your_simulation_model)")
        print("  network_metrics = processor.analyze_performance()")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()